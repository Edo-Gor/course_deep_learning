{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ox8dMXQ2_OEm"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 7.55\n",
    "#    Depth vs. breadth - II\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxlhkG0f_VvP"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BfA4BDX_f94"
   },
   "outputs": [],
   "source": [
    "# %% Import Iris dataset\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# Convert from pandas df to tensor\n",
    "data = torch.tensor(iris[iris.columns[0:4]].values).float()\n",
    "\n",
    "# Species to numbers\n",
    "labels = torch.zeros(len(data),dtype=torch.long)\n",
    "labels[iris.species=='setosa']     = 0\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica']  = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxoFhkp-AI0J"
   },
   "outputs": [],
   "source": [
    "# %% Class for the model\n",
    "#    Flexibly loop over model depth/breadth\n",
    "\n",
    "class ANNiris(nn.Module):\n",
    "    def __init__(self,nUnits,nLayers):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dictionary to store the layers\n",
    "        self.layers  = nn.ModuleDict()\n",
    "        self.nLayers = nLayers\n",
    "\n",
    "        # Input layer\n",
    "        self.layers['input'] = nn.Linear(4,nUnits)\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(nLayers):\n",
    "            self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)\n",
    "\n",
    "        # Output layer\n",
    "        self.layers['output'] = nn.Linear(nUnits,3)\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self,x):\n",
    "\n",
    "        # Input layer\n",
    "        x = self.layers['input'](x)\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(self.nLayers):\n",
    "            x = F.relu(self.layers[f'hidden{i}'](x))\n",
    "\n",
    "        # Output layer\n",
    "        x = self.layers['output'](x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1743208926564,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "7KEl8tmIEGhk",
    "outputId": "e6c6a647-6f4a-4f22-90a3-2c2a8e33b30f"
   },
   "outputs": [],
   "source": [
    "# %% Generate an instance of the model and check it\n",
    "\n",
    "nUnitsPerLayer = 12\n",
    "nLayers        = 4\n",
    "\n",
    "model = ANNiris(nUnitsPerLayer,nLayers)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743208928407,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "v6iX_z5PFGkj",
    "outputId": "bc13cf5d-c8fa-4312-e3f1-c31ec59a9138"
   },
   "outputs": [],
   "source": [
    "# %% Run the model to check its internal consistency\n",
    "\n",
    "# Samples and dimentions\n",
    "tmpx = torch.randn(10,4)\n",
    "\n",
    "# Run the model\n",
    "y = model(tmpx)\n",
    "\n",
    "# Show the output shape and the output\n",
    "print(y.shape)\n",
    "print( )\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf1iKwrOF-ou"
   },
   "outputs": [],
   "source": [
    "# %% Function to train the model\n",
    "\n",
    "def train_model(theModel):\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    loss_fun  = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(theModel.parameters(),lr=0.01)\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        # Forward pass\n",
    "        yHat = theModel(data)\n",
    "\n",
    "        # Loss computation\n",
    "        loss = loss_fun(yHat,labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Final pass and accuracy\n",
    "    predictions = theModel(data)\n",
    "    pred_labels = torch.argmax(predictions,axis=1)\n",
    "    tot_acc     = 100*torch.mean((pred_labels==labels).float())\n",
    "\n",
    "    # Total numbers of trainable parameters in the model\n",
    "    n_params = sum( p.numel() for p in theModel.parameters() if p.requires_grad )\n",
    "\n",
    "    # Function output\n",
    "    return tot_acc,n_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2866,
     "status": "ok",
     "timestamp": 1743208934643,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "DSGXC9UDJTSc",
    "outputId": "a9cf18bc-a9fa-4f06-845d-66caf1e60139"
   },
   "outputs": [],
   "source": [
    "# %% Test the function to train the model\n",
    "\n",
    "num_epochs = 2500\n",
    "output     = train_model(model)\n",
    "\n",
    "# Check output\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVHXUzwEKNKi"
   },
   "outputs": [],
   "source": [
    "# %% Parametric experiment on model depth and breadth\n",
    "#    This cell takes ~ 3 mins\n",
    "\n",
    "# Define model parameters (num of hidden layers and units per hidden layer)\n",
    "num_layers = range(1,6)\n",
    "num_units  = np.arange(4,101,3)\n",
    "\n",
    "# Preallocate output matrices\n",
    "accuracies = np.zeros(( len(num_units),len(num_layers) ))\n",
    "tot_params = np.zeros(( len(num_units),len(num_layers) ))\n",
    "\n",
    "# Number of trainig epochs\n",
    "num_epochs = 500\n",
    "\n",
    "# Buckle up, here's the experiment!\n",
    "for unit_i in range(len(num_units)):\n",
    "    for layer_i in range(len(num_layers)):\n",
    "\n",
    "        # Fresh model instance\n",
    "        model = ANNiris(num_units[unit_i],num_layers[layer_i])\n",
    "\n",
    "        # Run model and store outputs\n",
    "        tot_acc,n_params = train_model(model)\n",
    "\n",
    "        accuracies[unit_i,layer_i] = tot_acc\n",
    "        tot_params[unit_i,layer_i] = n_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1743208395678,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "SDChCngsL4Ox",
    "outputId": "c48a7989-72a3-4ee3-cab6-95c47e352c65"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "#    Accuracy as function of model depth\n",
    "\n",
    "fig,ax = plt.subplots(1,figsize=(12,6))\n",
    "\n",
    "ax.plot(num_units,accuracies,'o-',markerfacecolor='w',markersize=9)\n",
    "ax.plot(num_units[[0,-1]],[33,33],'--',color=[.75,.75,.75])\n",
    "ax.plot(num_units[[0,-1]],[67,67],'--',color=[.75,.75,.75])\n",
    "ax.legend([f'{n} hidden layers' for n in num_layers],loc='lower right')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Number of hidden units')\n",
    "ax.set_title('Accuracy over model depth and breadth')\n",
    "\n",
    "plt.savefig('figure81_number_hidden_units.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure81_number_hidden_units.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1743208420815,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "bt4f3jLXQJuo",
    "outputId": "27c952c7-2fae-43b5-f3ea-a0f6acab9aed"
   },
   "outputs": [],
   "source": [
    "# %% What about the number of parameters ?\n",
    "#    Notice how the number of trainable parameters does not correlate with the performace\n",
    "\n",
    "# Vectorise for convenience\n",
    "x = tot_params.flatten()\n",
    "y = accuracies.flatten()\n",
    "\n",
    "# Correlation\n",
    "r = np.corrcoef(x,y)[0,1]\n",
    "\n",
    "# Scatter plot\n",
    "plt.plot(x,y,'o')\n",
    "plt.xlabel('Number of parameters')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title(f'Correlation = {r:.2f}')\n",
    "\n",
    "plt.savefig('figure82_number_parameters.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure82_number_parameters.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk4vk_r1RVgZ"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 1\n",
    "#    Try it again with 1000 training epochs. Do the deeper models eventually learn?\n",
    "\n",
    "# The deeper models do improve, but the general pattern is preserved and the deeper\n",
    "# models keep underperforming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AD24Kc3IRdeh"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 2\n",
    "#    The categories are coded a \"0\", \"1\", and \"2\". Is there something special about those numbers?\n",
    "#    Recode the labels to be, e.g., 5, 10, and 17. Or perhaps -2, 0, and 2. Is the model still able to learn?\n",
    "\n",
    "# Nothing special, these are just dummy variables to code for different groups; however, the loss\n",
    "# function (cross-entropy) expects non-negative integers to label the classes, and for better code\n",
    "# readability it's probably better to stick to a range of the type: [0, num_classes-1]\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOF6zKV3oiPl1mL5GkhU4Hv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
