{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMgnUGzxK6KY"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 10.102\n",
    "#    Code challenge 13: Adam with L2 regularisation\n",
    "\n",
    "#    1) Start drom code from video 10.101 and 09.075\n",
    "#    2) Modify code from 10.101 to use Adam with L2 regularisation\n",
    "#    3) Use lr = 0.001 and batch_size = 32\n",
    "#    4) Test a range of L2 regularisation (from 0 to 0.1)\n",
    "#    5) Plot train and test accuracy against epochs for various L2 vals\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ve2hqLuTLPez"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas              as pd\n",
    "import scipy.stats         as stats\n",
    "import time\n",
    "\n",
    "from torch.utils.data                 import DataLoader,TensorDataset\n",
    "from sklearn.model_selection          import train_test_split\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from IPython                          import display\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KralTKgSi53"
   },
   "outputs": [],
   "source": [
    "# %% Create data\n",
    "\n",
    "# General params\n",
    "n_by_clust = 300\n",
    "blurring   = 1\n",
    "\n",
    "# Centroids\n",
    "A = [1,1]\n",
    "B = [5,1]\n",
    "C = [4,4]\n",
    "\n",
    "# Generate data\n",
    "a = [ A[0]+np.random.randn(n_by_clust)*blurring, A[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "b = [ B[0]+np.random.randn(n_by_clust)*blurring, B[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "c = [ C[0]+np.random.randn(n_by_clust)*blurring, C[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "\n",
    "# Labels\n",
    "labels_np = np.hstack(( np.zeros((n_by_clust)),\n",
    "                        np.ones((n_by_clust)),\n",
    "                        2*np.ones((n_by_clust)) ))\n",
    "\n",
    "# Data matrix\n",
    "data_np = np.hstack((a,b,c)).T\n",
    "\n",
    "# Data into PyTorch tensors (long format for CCE)\n",
    "data   = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1749217557337,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "sojlLsx1S5VY",
    "outputId": "b324f2a8-081a-4659-dc31-3d1dd424aae5"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'s',alpha=.75)\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'o',alpha=.75)\n",
    "plt.plot(data[np.where(labels==2)[0],0],data[np.where(labels==2)[0],1],'^',alpha=.75)\n",
    "\n",
    "plt.title('Some clusters')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('figure92_code_challenge_13.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure92_code_challenge_13.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxbW3cgUc4fV"
   },
   "outputs": [],
   "source": [
    "# %% Split into train and test data\n",
    "\n",
    "# Split with scikitlearn\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size=0.1)\n",
    "\n",
    "# Convert into PyTorch datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Convert into DataLoader objects\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pu05aN56fnRD"
   },
   "outputs": [],
   "source": [
    "# %% Create the model\n",
    "\n",
    "def gen_model(optimizer_alg,learning_rate,L2_lambda):\n",
    "\n",
    "    class model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            # Architecture\n",
    "            self.input  = nn.Linear(2,8)\n",
    "            self.hid1   = nn.Linear(8,8)\n",
    "            self.output = nn.Linear(8,3)\n",
    "\n",
    "        # Forward propagation\n",
    "        def forward(self,x):\n",
    "            x = F.relu(self.input(x))\n",
    "            x = F.relu(self.hid1(x))\n",
    "            x = self.output(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    # Model instance\n",
    "    ANN = model()\n",
    "\n",
    "    # Loss function and optimizer (get optimizer attribute)\n",
    "    loss_fun  = nn.CrossEntropyLoss()\n",
    "    opti_fun  = getattr( torch.optim,optimizer_alg )\n",
    "    optimizer = opti_fun(ANN.parameters(),lr=learning_rate,weight_decay=L2_lambda)\n",
    "\n",
    "    return ANN,loss_fun,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1749218760515,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "LA1U11Zxfn5A",
    "outputId": "9f94aef9-200d-42c9-a63b-3d46089ae336"
   },
   "outputs": [],
   "source": [
    "# %% Check model\n",
    "\n",
    "# Check weight decay\n",
    "optim = gen_model('Adam',0.01,0.05)[2]\n",
    "print(optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCEbJGc2ft5A"
   },
   "outputs": [],
   "source": [
    "# %% Function to train the model\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 50\n",
    "\n",
    "def train_model(optimizer_alg,learning_rate,L2_lambda):\n",
    "\n",
    "    # Model instance\n",
    "    ANN,loss_fun,optimizer = gen_model(optimizer_alg,learning_rate,L2_lambda)\n",
    "\n",
    "    # Initialise\n",
    "    losses    = []\n",
    "    train_acc = []\n",
    "    test_acc  = []\n",
    "\n",
    "    # Epochs loop\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        # Train mode on\n",
    "        ANN.train()\n",
    "\n",
    "        # Initialise and loop over batches\n",
    "        batch_losses = []\n",
    "        batch_acc    = []\n",
    "\n",
    "        for X,y in train_loader:\n",
    "\n",
    "            # Forward propagation and loss\n",
    "            yHat = ANN(X)\n",
    "            loss = loss_fun(yHat,y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute loss and accuracy from this batch\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            matches     = torch.argmax(yHat,axis=1) == y  # booleans\n",
    "            matches_num = matches.float()                 # convert to numbers\n",
    "            acc_percent = 100*torch.mean(matches_num)     # average and percent\n",
    "            batch_acc.append(acc_percent)\n",
    "\n",
    "        # Average train accuracy and losses from batches\n",
    "        train_acc.append(np.mean(batch_acc))\n",
    "        losses.append(np.mean(batch_losses))\n",
    "\n",
    "        # Test accuracy (turn autograd off)\n",
    "        ANN.eval()\n",
    "        X,y = next(iter(test_loader))\n",
    "        with torch.no_grad():\n",
    "            yHat = ANN(X)\n",
    "        test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "    return train_acc,test_acc,losses,ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0QdzFZzf8n4"
   },
   "outputs": [],
   "source": [
    "# %% Run experiment\n",
    "\n",
    "# Use only Andam and lr=0.001 for this code challenge (takes ~1 mins)\n",
    "L2_lambda      = np.linspace(0,0.1,6)\n",
    "batch_sizes    = [8,32,128]\n",
    "\n",
    "accuracy_train = np.zeros((num_epochs,len(L2_lambda),len(batch_sizes)))\n",
    "accuracy_test  = np.zeros((num_epochs,len(L2_lambda),len(batch_sizes)))\n",
    "\n",
    "for i,L2 in enumerate(L2_lambda):\n",
    "    for k,batch_size in enumerate(batch_sizes):\n",
    "\n",
    "        train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "        train_acc,test_acc,losses,ANN = train_model('Adam',0.001,L2)\n",
    "\n",
    "        accuracy_train[:,i,k] = np.array(train_acc)\n",
    "        accuracy_test[:,i,k]  = np.array(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndGcFD30jRdN"
   },
   "outputs": [],
   "source": [
    "# %% Functions for 1D smoothing filter\n",
    "\n",
    "# Improved for edge effects - adaptive window\n",
    "def smooth_adaptive(x,k):\n",
    "    smoothed = np.zeros_like(x)\n",
    "    half_k   = k // 2\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        start       = max(0, i-half_k)\n",
    "        end         = min(len(x), i+half_k + 1)\n",
    "        smoothed[i] = np.mean(x[start:end])\n",
    "\n",
    "    return smoothed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1749219713663,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "n0YcgXPCgSfd",
    "outputId": "2a86afa9-e184-448d-a2b4-823c18621ebc"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig,ax = plt.subplots(1,2,figsize=(1.5*6*phi,6))\n",
    "\n",
    "cmaps = plt.cm.plasma(np.linspace(.1,.9,len(L2_lambda)))\n",
    "for i in range(len(L2_lambda)):\n",
    "    ax[0].plot(smooth_adaptive(accuracy_train[:,i,1],5),color=cmaps[i])\n",
    "    ax[1].plot(smooth_adaptive(accuracy_test[:,i,1],5),color=cmaps[i])\n",
    "\n",
    "ax[0].set_title('Train accuracy')\n",
    "ax[1].set_title('Test accuracy')\n",
    "\n",
    "# Make the legend easier to read\n",
    "leglabels = [fun for i,fun in enumerate(L2_lambda)]\n",
    "\n",
    "# Common features\n",
    "for i in range(2):\n",
    "    ax[i].legend(leglabels)\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "    ax[i].set_ylabel('Accuracy (%)')\n",
    "    ax[i].set_ylim([30,101])\n",
    "    ax[i].grid()\n",
    "\n",
    "plt.suptitle('Batch size = 32')\n",
    "\n",
    "plt.savefig('figure93_code_challenge_13.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure93_code_challenge_13.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3FPw3LUZxLaQo2WjSKULZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
