{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeJ0xH8chEZl"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 6.35\n",
    "#    Code challenge 2: 2D gradient ascent\n",
    "\n",
    "#    1) Modify the 2D gradient descent into a gradient 'ascent' algorithm that\n",
    "#       finds local maxima\n",
    "#    2) There are at least two ways to do it, try to figure out both of them\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuqP9pOSiGWZ"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import sympy               as sym\n",
    "import copy\n",
    "\n",
    "from mpl_toolkits.mplot3d             import Axes3D\n",
    "from google.colab                     import files\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Q7hyLlaiTep"
   },
   "outputs": [],
   "source": [
    "# %% Define function\n",
    "\n",
    "# Use the function peaks as before\n",
    "\n",
    "def peaks(x,y):\n",
    "\n",
    "    # Expand to a 2D mesh\n",
    "    x,y = np.meshgrid(x,y)\n",
    "\n",
    "    z = 3*(1-x)**2 * np.exp(-(x**2) - (y+1)**2) \\\n",
    "        - 10*(x/5 - x**3 - y**5) * np.exp(-x**2 - y**2) \\\n",
    "        - 1/3*np.exp(-(x+1)**2 - y**2)\n",
    "\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1740935531615,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "7Jnz5_-XjO8z",
    "outputId": "8b1940b3-cc90-49a6-f9ce-6b674619de20"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "# Create landscape\n",
    "x = np.linspace(-3,3,201)\n",
    "y = np.linspace(-3,3,201)\n",
    "\n",
    "z = peaks(x,y)\n",
    "\n",
    "# Plot\n",
    "plt.imshow(z,extent=[x[0],x[-1],y[0],y[-1]],vmin=-5,vmax=5,origin='lower',cmap='jet')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 1228,
     "status": "ok",
     "timestamp": 1740935535039,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "DW3Arm3UjU-e",
    "outputId": "16f81929-974f-454f-be56-7b078b648857"
   },
   "outputs": [],
   "source": [
    "# %% Compute derivative with sympy\n",
    "\n",
    "# Create symbols and redefine function for sympy\n",
    "sx,sy = sym.symbols('sx,sy')\n",
    "sz    = 3*(1-sx)**2 * sym.exp(-(sx**2) - (sy+1)**2) \\\n",
    "        - 10*(sx/5 - sx**3 - sy**5) * sym.exp(-sx**2 - sy**2) \\\n",
    "        - 1/3*sym.exp(-(sx+1)**2 - sy**2)\n",
    "\n",
    "# Compute partial derivatives (.lambdify() transforms the symbolic function into a numpy usable function)\n",
    "df_x = sym.lambdify( (sx,sy),sym.diff(sz,sx),'sympy' )\n",
    "df_y = sym.lambdify( (sx,sy),sym.diff(sz,sy),'sympy' )\n",
    "\n",
    "# Example of partial derivative computation\n",
    "df_x(-1,-1).evalf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2552,
     "status": "ok",
     "timestamp": 1740935599715,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "AD7Gev6KjY9S",
    "outputId": "b35706be-e49d-441b-d724-1ac52628e4ec"
   },
   "outputs": [],
   "source": [
    "# %% Gradient 'ascent' in 2D\n",
    "#    Method 1, plus instead of minus\n",
    "#    Method 2, modify sz in the derivative by making it negative\n",
    "\n",
    "# 1) Random starting point (uniform between -2 and +2)\n",
    "local_max = np.random.rand(2)*4-2\n",
    "start_pnt = local_max[:]\n",
    "\n",
    "print(f'Random starting local maximum: {local_max}')\n",
    "\n",
    "# 2) Learning parameters\n",
    "learning_rate   = .01\n",
    "training_epochs = 1000\n",
    "\n",
    "# 3) Loop over epochs\n",
    "trajectory = np.zeros((training_epochs,2))\n",
    "\n",
    "for i in range(training_epochs):\n",
    "    gradient = np.array([ df_x(local_max[0],local_max[1]).evalf(),\n",
    "                          df_y(local_max[0],local_max[1]).evalf()\n",
    "                          ])\n",
    "    local_max       = local_max + gradient*learning_rate\n",
    "    trajectory[i,:] = local_max\n",
    "\n",
    "print(f'Estimated local maximum: {local_max}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 693,
     "status": "ok",
     "timestamp": 1740935602239,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "zPy_Up4gj6d8",
    "outputId": "b9b9cf89-5a63-4ce7-cb12-2c94310b534f"
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "plt.imshow(z,extent=[x[0],x[-1],y[0],y[-1]],vmin=-5,vmax=5,origin='lower',cmap='jet')\n",
    "plt.plot(start_pnt[0],start_pnt[1],'bs')\n",
    "plt.plot(local_max[0],local_max[1],'go')\n",
    "plt.plot(trajectory[:,0],trajectory[:,1],'g')\n",
    "plt.legend(['Rand start','Local max'])\n",
    "plt.suptitle('Random starting point')\n",
    "plt.title(f'Training epochs: {training_epochs} and learning rate: {learning_rate}')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.savefig('figure26_code_challenge_2.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure26_code_challenge_2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "executionInfo": {
     "elapsed": 304987,
     "status": "ok",
     "timestamp": 1740936334223,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "4ZuPi0YAwRQd",
    "outputId": "aec92a89-6cf4-45fa-c057-f151028e79a3"
   },
   "outputs": [],
   "source": [
    "# %% Visualise the basins of attraction for the gradient descent algorithm\n",
    "\n",
    "# Grid for function visualization\n",
    "x = np.linspace(-4,4,201)\n",
    "y = np.linspace(-4,4,201)\n",
    "\n",
    "# Gradient descent parameters\n",
    "learning_rate   = 0.01\n",
    "training_epochs = 100\n",
    "\n",
    "# Generate multiple starting points in a 25x25 grid\n",
    "start_x      = np.linspace(-2.5,2.5,25)\n",
    "start_y      = np.linspace(-2.5,2.5,25)\n",
    "start_points = np.array(np.meshgrid(start_x,start_y)).T.reshape(-1,2)\n",
    "\n",
    "# Plot function\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(z,extent=[x[0],x[-1],y[0],y[-1]],vmin=-5,vmax=5,origin='lower',cmap='jet')\n",
    "\n",
    "# Run gradient descent for each starting point\n",
    "for start_pnt in start_points:\n",
    "    local_max  = start_pnt.copy()\n",
    "    trajectory = np.zeros((training_epochs, 2))\n",
    "\n",
    "    for i in range(training_epochs):\n",
    "        gradient = np.array([df_x(local_max[0],local_max[1]),\n",
    "                             df_y(local_max[0],local_max[1])\n",
    "                             ])\n",
    "        local_max       = local_max + gradient*learning_rate\n",
    "        trajectory[i,:] = local_max\n",
    "\n",
    "    # Plot trajectory\n",
    "    plt.plot(start_pnt[0],start_pnt[1],'bs',markersize=2)\n",
    "    plt.plot(local_max[0],local_max[1],'ko',markersize=3)\n",
    "    plt.plot(trajectory[:,0],trajectory[:,1],'g',alpha=0.5)\n",
    "\n",
    "plt.legend(['Start point','Local max'])\n",
    "plt.suptitle('Basins of Attraction for Gradient Ascent')\n",
    "plt.title(f'Training epochs: {training_epochs}, Learning rate: {learning_rate}')\n",
    "\n",
    "plt.savefig('figure32_code_challenge_2.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure32_code_challenge_2.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMdobiG/hyeedujYgh2W9WJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
