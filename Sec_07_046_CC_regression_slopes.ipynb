{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ADbMOs1T82q"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 7.46\n",
    "#    Code challenge 4: manipulate regression slopes\n",
    "\n",
    "#    1) Write a fuction that builds and train the model, and outputs final\n",
    "#       prediction and loss\n",
    "#    2) Write a function that creates data x and output y; x same as previous\n",
    "#       video, y = m*x + randn/2, n = 50\n",
    "#    3) In a parametric experiment, vary the slope from -2 to +2 in 21 steps,\n",
    "#       repeat the experiment 50 times and average over them.\n",
    "#    4) Plot both loss and accuray as function of slopes\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8xLfw3uT-Ll"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import copy\n",
    "\n",
    "from google.colab                     import files\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tZNH5z6Wmem"
   },
   "outputs": [],
   "source": [
    "# %% Functions\n",
    "\n",
    "# Model function\n",
    "def build_model(x,y):\n",
    "\n",
    "    # Build the model\n",
    "    ANNreg = nn.Sequential(\n",
    "                nn.Linear(1,1),   # input layer (num inputs, num outputs)\n",
    "                nn.ReLU(),        # activation function\n",
    "                nn.Linear(1,1)    # output layer (num inputs, num outputs)\n",
    "                )\n",
    "\n",
    "    # Training parameters\n",
    "    learning_rate = 0.05\n",
    "    loss_fun  = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(ANNreg.parameters(),lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 500\n",
    "    losses = torch.zeros(num_epochs)\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        yHat = ANNreg(x)\n",
    "\n",
    "        loss = loss_fun(yHat,y)\n",
    "        losses[epoch_i] = loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Final forward pass and loss\n",
    "    predictions = ANNreg(x)\n",
    "    testloss    = (predictions-y).pow(2).mean()\n",
    "\n",
    "    # Compute accuracy as correlation between prediction and data\n",
    "    accuracy = np.corrcoef(y.T,predictions.detach().T)[0,1]\n",
    "\n",
    "    return accuracy,testloss\n",
    "\n",
    "# Data function\n",
    "def gen_data(m):\n",
    "\n",
    "    n = 50\n",
    "    x = torch.randn(n,1)\n",
    "    y = m*x + torch.randn(n,1)/2\n",
    "\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6h3CGYhiYiC0"
   },
   "outputs": [],
   "source": [
    "# %% Parametric experiment on slopes\n",
    "\n",
    "# Around 4 min run\n",
    "iterations = 50\n",
    "slopes     = np.linspace(-2,2,21)\n",
    "\n",
    "accuracies = torch.zeros(len(slopes))\n",
    "losses     = torch.zeros(len(slopes))\n",
    "\n",
    "for slop_idx,slope_val in enumerate(slopes):\n",
    "\n",
    "    temp_accuracies = torch.zeros(iterations)\n",
    "    temp_losses     = torch.zeros(iterations)\n",
    "\n",
    "    for iter in range(iterations):\n",
    "\n",
    "        # Call functions\n",
    "        x,y     = gen_data(slope_val)\n",
    "        acc,los = build_model(x,y)\n",
    "\n",
    "        # Store temporary accuracies and losses\n",
    "        temp_accuracies[iter] = acc\n",
    "        temp_losses[iter]     = los\n",
    "\n",
    "    # Compute average acc and loss for iter, .nanmean() exclude nan datapoints that might occur\n",
    "    accuracies[slop_idx] = temp_accuracies.detach().nanmean()\n",
    "    losses[slop_idx]     = temp_losses.detach().nanmean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1741612172655,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "6AjI-g1JfnQj",
    "outputId": "dad3c0e1-a2ba-4a01-b61f-ab9fb7251a96"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "ax[0].plot(slopes,losses,'b-',label='Loss')\n",
    "ax[0].set_xlabel('Slope')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Slopes against model losses')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(slopes,accuracies,'r-',label='Accuracy')\n",
    "ax[1].set_xlabel('Slope')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_title('Slopes against model perfomance')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figure14_code_challenge_4.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure14_code_challenge_4.png')\n",
    "\n",
    "# Nota Bene:\n",
    "# The graphs show nicely how the losses decrease for low correlations, but also the performance\n",
    "# becomes quite crappy for correlations close to zero. This is due to the fact that the variance is\n",
    "# simply larger for steeper slopes; in other words, losses cannt be compared on different data\n",
    "# unless appropriately normalised. Performace on the other hand drops for low correlations because\n",
    "# x is not so informative about y, and the model thus not have much information about y; this leads to\n",
    "# an important point, ANNs do not predict data values, they only learn relationships across variables.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM60S+Hg/guXhKS5K+Ye/s1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
