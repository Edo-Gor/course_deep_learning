{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMgnUGzxK6KY"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 10.101\n",
    "#    Code challenge 12: optimizer and ... someting\n",
    "\n",
    "#    1) Start drom code from video 10.100\n",
    "#    2) Compare performance of the three optimizers using a range of lr\n",
    "#    3) Plot test accuracy (avg last 10 epochs) against learning rates\n",
    "#    4) Use log spaced lr (from 0.0001 to 0.1, 20 vals)\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ve2hqLuTLPez"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas              as pd\n",
    "import scipy.stats         as stats\n",
    "import time\n",
    "\n",
    "from torch.utils.data                 import DataLoader,TensorDataset\n",
    "from sklearn.model_selection          import train_test_split\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from IPython                          import display\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KralTKgSi53"
   },
   "outputs": [],
   "source": [
    "# %% Create data\n",
    "\n",
    "# General params\n",
    "n_by_clust = 300\n",
    "blurring   = 1\n",
    "\n",
    "# Centroids\n",
    "A = [1,1]\n",
    "B = [5,1]\n",
    "C = [4,4]\n",
    "\n",
    "# Generate data\n",
    "a = [ A[0]+np.random.randn(n_by_clust)*blurring, A[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "b = [ B[0]+np.random.randn(n_by_clust)*blurring, B[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "c = [ C[0]+np.random.randn(n_by_clust)*blurring, C[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "\n",
    "# Labels\n",
    "labels_np = np.hstack(( np.zeros((n_by_clust)),\n",
    "                        np.ones((n_by_clust)),\n",
    "                        2*np.ones((n_by_clust)) ))\n",
    "\n",
    "# Data matrix\n",
    "data_np = np.hstack((a,b,c)).T\n",
    "\n",
    "# Data into PyTorch tensors (long format for CCE)\n",
    "data   = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1749157322064,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "sojlLsx1S5VY",
    "outputId": "b9151474-e096-4338-885c-15fa1dd73e61"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'s',alpha=.75)\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'o',alpha=.75)\n",
    "plt.plot(data[np.where(labels==2)[0],0],data[np.where(labels==2)[0],1],'^',alpha=.75)\n",
    "\n",
    "plt.title('Some clusters')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('figure87_code_challenge_12.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure87_code_challenge_12.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeKupuRqMXWL"
   },
   "outputs": [],
   "source": [
    "# %% Split into train and test data\n",
    "\n",
    "# Split with scikitlearn\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size=0.1)\n",
    "\n",
    "# Convert into PyTorch datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Convert into DataLoader objects\n",
    "batch_size   = 16\n",
    "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp2y6xFMMfsL"
   },
   "outputs": [],
   "source": [
    "# %% Create the model\n",
    "\n",
    "def gen_model(optimizer_alg,learning_rate):\n",
    "\n",
    "    class model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            # Architecture\n",
    "            self.input  = nn.Linear(2,8)\n",
    "            self.hid1   = nn.Linear(8,8)\n",
    "            self.output = nn.Linear(8,3)\n",
    "\n",
    "        # Forward propagation\n",
    "        def forward(self,x):\n",
    "            x = F.relu(self.input(x))\n",
    "            x = F.relu(self.hid1(x))\n",
    "            x = self.output(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    # Model instance\n",
    "    ANN = model()\n",
    "\n",
    "    # Loss function and optimizer (get optimizer attribute)\n",
    "    loss_fun  = nn.CrossEntropyLoss()\n",
    "    opti_fun  = getattr( torch.optim,optimizer_alg )\n",
    "    optimizer = opti_fun(ANN.parameters(),lr=learning_rate)\n",
    "\n",
    "    return ANN,loss_fun,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9106,
     "status": "ok",
     "timestamp": 1749157389907,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "IDGEPCweM1un",
    "outputId": "edfd6131-a9d7-4ae0-ad04-8b54014dfc69"
   },
   "outputs": [],
   "source": [
    "# %% Test momentum and lr\n",
    "\n",
    "# Try 'SGD', 'RMSprop', and 'Adam'\n",
    "optim = gen_model('Adam',0.01)[2]\n",
    "print(optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2PfHUWfNNiN"
   },
   "outputs": [],
   "source": [
    "# %% Function to train the model\n",
    "\n",
    "def train_model(optimizer_alg,learning_rate):\n",
    "\n",
    "    # Epochs\n",
    "    num_epochs = 50\n",
    "\n",
    "    # Model instance\n",
    "    ANN,loss_fun,optimizer = gen_model(optimizer_alg,learning_rate)\n",
    "\n",
    "    # Initialise\n",
    "    losses    = []\n",
    "    train_acc = []\n",
    "    test_acc  = []\n",
    "\n",
    "    # Epochs loop\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        # Train mode on\n",
    "        ANN.train()\n",
    "\n",
    "        # Initialise and loop over batches\n",
    "        batch_losses = []\n",
    "        batch_acc    = []\n",
    "\n",
    "        for X,y in train_loader:\n",
    "\n",
    "            # Forward propagation and loss\n",
    "            yHat = ANN(X)\n",
    "            loss = loss_fun(yHat,y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute loss and accuracy from this batch\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            matches     = torch.argmax(yHat,axis=1) == y  # booleans\n",
    "            matches_num = matches.float()                 # convert to numbers\n",
    "            acc_percent = 100*torch.mean(matches_num)     # average and percent\n",
    "            batch_acc.append(acc_percent)\n",
    "\n",
    "        # Average train accuracy and losses from batches\n",
    "        train_acc.append(np.mean(batch_acc))\n",
    "        losses.append(np.mean(batch_losses))\n",
    "\n",
    "        # Test accuracy (turn autograd off)\n",
    "        ANN.eval()\n",
    "        X,y = next(iter(test_loader))\n",
    "        with torch.no_grad():\n",
    "            yHat = ANN(X)\n",
    "        test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "    return train_acc,test_acc,losses,ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d38GjNQP6BdO"
   },
   "outputs": [],
   "source": [
    "# %% Parametric experiment over three optimizer and learning rates\n",
    "\n",
    "# Takes ~6 mins\n",
    "optimizers        = ['SGD','RMSprop','Adam']\n",
    "learning_rates    = np.logspace(-4,-1,20)\n",
    "performance_train = np.zeros((len(optimizers),len(learning_rates)))\n",
    "performance_test  = np.zeros((len(optimizers),len(learning_rates)))\n",
    "\n",
    "for i,optimizer in enumerate(optimizers):\n",
    "    for j,lr in enumerate(learning_rates):\n",
    "\n",
    "        train_acc,test_acc,losses,ANN = train_model(optimizer,lr)\n",
    "\n",
    "        performance_train[i,j] = np.mean(train_acc[-10:])\n",
    "        performance_test[i,j]  = np.mean(test_acc[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1749160833575,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "eXWtEkBZ74Z6",
    "outputId": "191a0106-20aa-453f-d956-8406ed4a5176"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "# Train data\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "for i,optimizer in enumerate(optimizers):\n",
    "    plt.plot(learning_rates,performance_train[i,:],'o-',alpha=.75,label=f'{optimizer}')\n",
    "\n",
    "plt.title('Optimizers over learning rates - Training')\n",
    "plt.xlabel('Learning rates')\n",
    "plt.ylabel('Mean accuracy (last 10 epochs)')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('figure88_code_challenge_12.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure88_code_challenge_12.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1749160861891,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "7IPeNxaQ8GtE",
    "outputId": "45e6e05e-b771-4cd5-d870-f875cb95b00e"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "# Train data\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "for i,optimizer in enumerate(optimizers):\n",
    "    plt.plot(learning_rates,performance_test[i,:],'o-',alpha=.75,label=f'{optimizer}')\n",
    "\n",
    "plt.title('Optimizers over learning rates - Test')\n",
    "plt.xlabel('Learning rates')\n",
    "plt.ylabel('Mean accuracy (last 10 epochs)')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('figure89_code_challenge_12.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure89_code_challenge_12.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIcsRUgJ_xrK"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 1\n",
    "#    Which optimizer is best for quick learning? Re-run the code but average accuracy in the FIRST 10 training epochs\n",
    "#    instead of the FINAL 10 training epochs.\n",
    "\n",
    "# Similar picture, even in this case RMSprop and Adam allow for a faster learning,\n",
    "# presumably again because of the adaptive lr intrinsically implemented in these\n",
    "# two algorithms\n",
    "\n",
    "# Takes ~6 mins\n",
    "optimizers        = ['SGD','RMSprop','Adam']\n",
    "learning_rates    = np.logspace(-4,-1,20)\n",
    "performance_train = np.zeros((len(optimizers),len(learning_rates)))\n",
    "performance_test  = np.zeros((len(optimizers),len(learning_rates)))\n",
    "\n",
    "for i,optimizer in enumerate(optimizers):\n",
    "    for j,lr in enumerate(learning_rates):\n",
    "\n",
    "        train_acc,test_acc,losses,ANN = train_model(optimizer,lr)\n",
    "\n",
    "        performance_train[i,j] = np.mean(train_acc[:10])\n",
    "        performance_test[i,j]  = np.mean(test_acc[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byxYYzRaAI24"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 2\n",
    "#    Similar question but for batch size. Try using batch sizes ranging from 2**4 (16) to 2**7 (128).\n",
    "\n",
    "# What is this? A meta-parametric experiment! I set it up with a (monstruous)\n",
    "# triple for loop to also run over some batch sizes. As one would expect,\n",
    "# smaller batch sizes produces higher accuracies in general, but there's\n",
    "# probably also an interaction with the effect of optimizer, with basic SGD\n",
    "# performing worse than RMSprop or Adam. In other words, RMSprop and Adam are\n",
    "# more robust to variations in batch sizes, and (assuming the data make it\n",
    "# appropriate) one could use larger batch sizes to save up memory and\n",
    "# computation time without too many concerns (?)\n",
    "\n",
    "# Parametric experiment over three optimizer, learning rates and batch sizes\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size=0.1)\n",
    "\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n",
    "\n",
    "# Takes ~11 mins\n",
    "optimizers        = ['SGD','RMSprop','Adam']\n",
    "learning_rates    = np.logspace(-4,-1,20)\n",
    "batch_sizes       = [16,32,64,128]\n",
    "performance_train = np.zeros((len(optimizers),len(learning_rates),len(batch_sizes)))\n",
    "performance_test  = np.zeros((len(optimizers),len(learning_rates),len(batch_sizes)))\n",
    "\n",
    "for i,optimizer in enumerate(optimizers):\n",
    "    for j,lr in enumerate(learning_rates):\n",
    "        for k,batch_size in enumerate(batch_sizes):\n",
    "\n",
    "            train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "            train_acc,test_acc,losses,ANN = train_model(optimizer,lr)\n",
    "\n",
    "            performance_train[i,j,k] = np.mean(train_acc[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "executionInfo": {
     "elapsed": 3621,
     "status": "ok",
     "timestamp": 1749163570932,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "EVkmLZWzGdYd",
    "outputId": "67aaa55c-4d3d-4ffb-caa4-60d83e5cfb58"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "# Train data\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig,ax = plt.subplots(1,3,figsize=(2*6*phi,6))\n",
    "\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "cmaps = plt.cm.plasma(np.linspace(.1,.9,len(batch_sizes)))\n",
    "\n",
    "# Plot SGD\n",
    "for i,batch_size in enumerate(batch_sizes):\n",
    "    style = line_styles[i % len(line_styles)]\n",
    "    ax[0].plot(learning_rates,performance_train[0,:,i],style+'o',color=cmaps[i],alpha=.75,label=f'SGD - Batch size: {batch_size}')\n",
    "    ax[0].set_title('SGD')\n",
    "    ax[0].set_xlabel('Learning rates')\n",
    "    ax[0].set_ylabel('Mean accuracy (last 10 epochs)')\n",
    "    ax[0].set_xscale('log')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "\n",
    "# Plot RMSprop\n",
    "for i,batch_size in enumerate(batch_sizes):\n",
    "    style = line_styles[i % len(line_styles)]\n",
    "    ax[1].plot(learning_rates,performance_train[1,:,i],style+'o',color=cmaps[i],label=f'RMSprop - Batch size: {batch_size}')\n",
    "    ax[1].set_title('RMSprop')\n",
    "    ax[1].set_xlabel('Learning rates')\n",
    "    ax[1].set_ylabel('Mean accuracy (last 10 epochs)')\n",
    "    ax[1].set_xscale('log')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "# Plot Adam\n",
    "for i,batch_size in enumerate(batch_sizes):\n",
    "    style = line_styles[i % len(line_styles)]\n",
    "    ax[2].plot(learning_rates,performance_train[2,:,i],style+'o',color=cmaps[i],label=f'Adam - Batch size: {batch_size}')\n",
    "    ax[2].set_title('Adam')\n",
    "    ax[2].set_xlabel('Learning rates')\n",
    "    ax[2].set_ylabel('Mean accuracy (last 10 epochs)')\n",
    "    ax[2].set_xscale('log')\n",
    "    ax[2].legend()\n",
    "    ax[2].grid(True)\n",
    "\n",
    "plt.suptitle('Optimizers over learning rates - Train')\n",
    "\n",
    "plt.savefig('figure91_code_challenge_12_extra2.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure91_code_challenge_12_extra2.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzcbS/nZtcR+2IMeUNXLx0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
