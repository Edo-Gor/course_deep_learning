{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PxmK3ACZBwf"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 6.33\n",
    "#    Code challenge 1: Unfortunate starting value\n",
    "\n",
    "#    1) Define function and look for minimum as in previous code\n",
    "#    2) Hard-code starting value of x = 0\n",
    "#    3) Additional exercises\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QK7k_P3cSzw"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import copy\n",
    "\n",
    "from google.colab                     import files\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tck9ni73cXUR"
   },
   "outputs": [],
   "source": [
    "# %% Define function\n",
    "\n",
    "def fx(x):\n",
    "    return np.cos(2*np.pi*x) + x**2\n",
    "\n",
    "def df(x):\n",
    "    return 2*(x - np.pi*np.sin(2*np.pi*x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1740862818370,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "-7Omra0mhUkK",
    "outputId": "46c5299a-c13d-4352-ab6a-82f6f69f6aa4"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "x = np.linspace(-2,2,2001)\n",
    "\n",
    "plt.plot(x,fx(x),x,df(x))\n",
    "plt.xlim(x[[0,-1]])\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend([\"f(x)\",\"f'(x)\"])\n",
    "plt.title('A function and its derivative')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1740853310266,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "N6qk1UIuikmO",
    "outputId": "747df1ca-0556-4f91-c4ef-0f1276b1c057"
   },
   "outputs": [],
   "source": [
    "# %% Gradient descent\n",
    "\n",
    "# Random starting point\n",
    "local_min   = np.random.choice(x,1).item()\n",
    "learn_rate  = 0.01\n",
    "train_epoch = 100\n",
    "\n",
    "print(f'Random starting local mininum: {local_min:.8f}')\n",
    "\n",
    "for i in range(train_epoch):\n",
    "    gradient  = df(local_min)\n",
    "    local_min = local_min - gradient*learn_rate\n",
    "\n",
    "print(f'Estimated local mininum: {local_min:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1740862823773,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "7m-gv_PSjohe",
    "outputId": "3c49190e-0f2b-4344-b65a-1d1a348d445e"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "plt.plot(x,fx(x),x,df(x))\n",
    "plt.plot(local_min,df(local_min),'ro')\n",
    "plt.plot(local_min,fx(local_min),'ro')\n",
    "\n",
    "plt.xlim(x[[0,-1]])\n",
    "plt.grid()\n",
    "plt.xlabel('')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend([\"f(x)\",\"f'(x)\",\"f(x) min\"])\n",
    "plt.suptitle('A function and its derivative')\n",
    "plt.title('Empirical local minimum: %s' %np.round(local_min,4))\n",
    "\n",
    "plt.savefig('figure7_code_challenge_1.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure7_code_challenge_1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1740851575774,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "h4gpjVgul1jx",
    "outputId": "2cb90edb-0712-4cb6-901f-0f0007b0632e"
   },
   "outputs": [],
   "source": [
    "# %% Gradient descent\n",
    "\n",
    "# Fixed starting point (here at a local maximum)\n",
    "local_min   = 0.0001\n",
    "learn_rate  = 0.01\n",
    "train_epoch = 100\n",
    "\n",
    "print(f'Random starting local mininum: {local_min:.8f}')\n",
    "\n",
    "for i in range(train_epoch):\n",
    "    gradient  = df(local_min)\n",
    "    local_min = local_min - gradient*learn_rate\n",
    "\n",
    "print(f'Estimated local mininum: {local_min:.8f}')\n",
    "\n",
    "# This is called vanishing gradient, the derivative is already so close to zero\n",
    "# that there is no learning at all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1740852197281,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -60
    },
    "id": "sdyNeLz_mAGF",
    "outputId": "01c24c17-da25-433a-8c70-d30d26936e99"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "plt.plot(x,fx(x),x,df(x))\n",
    "plt.plot(local_min,df(local_min),'ro')\n",
    "plt.plot(local_min,fx(local_min),'ro')\n",
    "\n",
    "plt.xlim(x[[0,-1]])\n",
    "plt.grid()\n",
    "plt.xlabel('')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend([\"f(x)\",\"f'(x)\",\"f(x) min\"])\n",
    "plt.suptitle('A function and its derivative')\n",
    "plt.title('Empirical local minimum: %s' %np.round(local_min,4))\n",
    "\n",
    "plt.savefig('figure9_code_challenge_1.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure9_code_challenge_1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RK43K4s0nwru"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 1\n",
    "#    The derivative has a multiplicative factor of 2 in it. Is that constant necessary for the accuracy of the g.d. result?\n",
    "#    Try removing that '2' from the derivative and see whether the model can still find the minimum. Before running the\n",
    "#    code, think about what you expect to happen. Does reality match your expectations? Why is (or isn't) that factor necessary?\n",
    "\n",
    "# No, the constant only stretches the derivative along the y axis and change its steepness, but doesn't change the points where\n",
    "# the derivative equals zero; however, in the context of numerical discrete computations, maybe making the derivative steeper makes\n",
    "# it faster to reach the area of a local minimum, and potentially allows for a more numerically stable output (not to mention\n",
    "# that it's also the actual derivative anyway)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUvWabo1oBRL"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 2\n",
    "#    What about the factor of '2' inside the np.sin() function? Is that important? Can you get an accurate result if you\n",
    "#    remove it?\n",
    "\n",
    "# No. If you remove that factor the periodicity of the wave in the derivative will be messed up, meaning that the deriative will no longer\n",
    "# identify the minima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoBjqnzHoBhO"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 3\n",
    "#    Try setting the initial value to a small but non-zero number, e.g., .0001 or -.0001. Does that help the solution?\n",
    "\n",
    "# In this case the function is a simple cosine with an superimposed parabola, meaning that the local maxima are technically\n",
    "# just one point at the peak of the waves, and an initial value just slightly different from zero is enough to knock the gradient\n",
    "# downhill. However, if the loss function had a more extended area with no growth (or not enough training epochs), this trick\n",
    "# might not be enough\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPOZBoZyhSXAqmlD5djdGve",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
