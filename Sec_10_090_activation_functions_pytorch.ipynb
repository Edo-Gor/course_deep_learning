{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yveCkLJIDJYR"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 10.90\n",
    "#    Activation functions in PyTorch\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gD2FwLtjDeQv"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas              as pd\n",
    "import scipy.stats         as stats\n",
    "import time\n",
    "\n",
    "from torch.utils.data                 import DataLoader,TensorDataset\n",
    "from sklearn.model_selection          import train_test_split\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from IPython                          import display\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaC96G-i6l_8"
   },
   "outputs": [],
   "source": [
    "# %% Variable and fuction\n",
    "\n",
    "# Variable\n",
    "x = torch.linspace(-3,3,101)\n",
    "\n",
    "# Function returning the activated input\n",
    "def NN_output(act_fun):\n",
    "\n",
    "    # Get activation function type and replace torch.relu with torch.<act_fun>\n",
    "    # getattr() = get-attribute of an object or instance of a class\n",
    "    act_fun = getattr(torch,act_fun)\n",
    "\n",
    "    return act_fun(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1748554394518,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "ahmCNuGJ7jnz",
    "outputId": "89982691-5e65-43a9-9e54-e3c4c4e4034b"
   },
   "outputs": [],
   "source": [
    "# %% Activation functions\n",
    "\n",
    "activation_funs = ['relu','sigmoid','tanh']\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "for act_fun in activation_funs:\n",
    "    plt.plot(x,NN_output(act_fun),label=act_fun,linewidth=3)\n",
    "\n",
    "plt.plot(x[[0,-1]],[0,0],'--',color=[.7,.7,.7])\n",
    "plt.plot(x[[0,-1]],[1,1],'--',color=[.7,.7,.7])\n",
    "plt.plot([0,0],[-1,3],'--',color=[.7,.7,.7])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\sigma(x)$')\n",
    "plt.title('Various activation functions')\n",
    "plt.xlim(x[[0,-1]])\n",
    "plt.ylim([-1,3])\n",
    "\n",
    "plt.savefig('figure26_activation_functions_pytorch.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure26_activation_functions_pytorch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNSTiZDt-Dfh"
   },
   "outputs": [],
   "source": [
    "# %% More about activation functions in PyTorch\n",
    "\n",
    "# Function returning the activated input\n",
    "def NN_output(act_fun):\n",
    "\n",
    "    # Get activation function type and replace torch.nn.relu with torch.nn.<act_fun>\n",
    "    # getattr() = get-attribute of an object or instance of a class\n",
    "    act_fun = getattr(torch.nn,act_fun)\n",
    "\n",
    "    return act_fun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1748554902861,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "ZQZLJNKX-cwE",
    "outputId": "10f3b02d-d8ab-45b4-db9f-04c7726fc3f6"
   },
   "outputs": [],
   "source": [
    "# %% Activation functions\n",
    "\n",
    "activation_funs = ['ReLU6','Hardshrink','LeakyReLU']\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "for act_fun in activation_funs:\n",
    "    plt.plot(x,NN_output(act_fun)(x),label=act_fun,linewidth=3)\n",
    "\n",
    "plt.plot(x[[0,-1]],[0,0],'--',color=[.7,.7,.7])\n",
    "plt.plot(x[[0,-1]],[1,1],'--',color=[.7,.7,.7])\n",
    "plt.plot([0,0],[-1,3],'--',color=[.7,.7,.7])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\sigma(x)$')\n",
    "plt.title('Various activation functions')\n",
    "plt.xlim(x[[0,-1]])\n",
    "plt.ylim([-1,3])\n",
    "plt.ylim([-.1,.1])\n",
    "\n",
    "plt.savefig('figure27_activation_functions_pytorch.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure27_activation_functions_pytorch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1748555106792,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "7rqVKtqr_2tx",
    "outputId": "d211ddc8-aff8-430f-94c6-b6b441646690"
   },
   "outputs": [],
   "source": [
    "# %% ReLU6 more in detail\n",
    "\n",
    "x = torch.linspace(-3,9,101)\n",
    "relu6 = torch.nn.ReLU6()\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "plt.plot(x,relu6(x),linewidth=3)\n",
    "\n",
    "plt.plot(x[[0,-1]],[0,0],'--',color=[.7,.7,.7])\n",
    "plt.plot(x[[0,-1]],[1,1],'--',color=[.7,.7,.7])\n",
    "plt.plot([0,0],[-1,6],'--',color=[.7,.7,.7])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\sigma(x)$')\n",
    "plt.title('ReLU6')\n",
    "\n",
    "plt.savefig('figure29_activation_functions_pytorch.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure29_activation_functions_pytorch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1748555410377,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "cYC4zUWzAbgb",
    "outputId": "1c5aedf3-7422-495f-e98c-80e8cba66eb7"
   },
   "outputs": [],
   "source": [
    "# %% Difference between torch and torch.nn\n",
    "\n",
    "x = torch.linspace(-3,3,21)\n",
    "\n",
    "# In torch (input values directly)\n",
    "y1 = torch.relu(x)\n",
    "\n",
    "# In torch.nn (wrapper)\n",
    "f  = torch.nn.ReLU()\n",
    "y2 = f(x)\n",
    "\n",
    "# Plotting\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "plt.plot(x,y1,'o',label='torch.relu',linewidth=3)\n",
    "plt.plot(x,y2,'x',label='torch.nn.ReLU',linewidth=3)\n",
    "\n",
    "plt.plot(x[[0,-1]],[0,0],'--',color=[.7,.7,.7])\n",
    "plt.plot(x[[0,-1]],[1,1],'--',color=[.7,.7,.7])\n",
    "plt.plot([0,0],[-1,3],'--',color=[.7,.7,.7])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\sigma(x)$')\n",
    "plt.title('Torch vs. torch.nn')\n",
    "\n",
    "plt.savefig('figure30_activation_functions_pytorch.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure30_activation_functions_pytorch.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQsU01WFB1RZ"
   },
   "outputs": [],
   "source": [
    "# %% Activation functions in PyTorch\n",
    "\n",
    "# List of activation functions in PyTorch:\n",
    "#  https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZA82iJ_CCpt"
   },
   "outputs": [],
   "source": [
    "# %% Exercises\n",
    "\n",
    "# The goal of these explorations is to help you appreciate the remarkably diverse nonlinear shapes that a node can produce.\n",
    "# All explorations use the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1748558334578,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "Tjyk4BPfCHXj",
    "outputId": "a3f8554a-ec63-42bf-d1ed-379e5567732a"
   },
   "outputs": [],
   "source": [
    "# %% Code\n",
    "\n",
    "# Create input  ...\n",
    "x1 = torch.linspace(-1,1,21)\n",
    "x2 = abs(x1)\n",
    "\n",
    "# ... and corresponding weights\n",
    "w1 = .4\n",
    "w2 = .6\n",
    "\n",
    "# Linear combination ...\n",
    "linpart = x1*w1 + x2*w2\n",
    "\n",
    "# ... and nonlinear output\n",
    "y = torch.relu(linpart)\n",
    "\n",
    "# Plotting\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "plt.plot(x1,linpart,'bo-',label='Linear combinantion')\n",
    "plt.plot(x1,y,'rs',label='Nonlinear output')\n",
    "\n",
    "plt.plot(x[[0,-1]],[0,0],'--',color=[.7,.7,.7])\n",
    "plt.plot(x[[0,-1]],[1,1],'--',color=[.7,.7,.7])\n",
    "plt.plot([0,0],[-1,3],'--',color=[.7,.7,.7])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\sigma(x)$')\n",
    "\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])\n",
    "\n",
    "plt.savefig('figure31_activation_functions_pytorch_extra1.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure31_activation_functions_pytorch_extra1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezfVR9ayDTCR"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 1\n",
    "#    Look through the code to make sure you understand what it does (linear weighted combination -> nonlinear function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puK0TA7eD5Ca"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 2\n",
    "#    Set x2=x1**2 and run the code. Then set one of the weights to be negative. Then set the negative weight to be close\n",
    "#    to zero (e.g., -.01) with the positive weight relatively large (e.g., .8). Then swap the signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4wBE1RjD7on"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 3\n",
    "#    Set x2=x1**2, and set the weights to be .4 and .6. Now set w2=.6 (you might want to zoom in on the y-axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giMpIpxtD8_N"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 4\n",
    "#    Set x2 to be the absolute value of x1 and both weights positive. Then set w2=-.6. Why does w2<0 have such a big impact?\n",
    "#    More generally, under what conditions are the input and output identical?\n",
    "\n",
    "# The negative weight makes the entire linpart negative, so that ReLU in that case returns nothing\n",
    "# but zeros. More in general, the linear combinantion and the non-linear pass of a ReLu are\n",
    "# identical if the linear combinantion is already storing only non-negative values, in that case\n",
    "# ReLU returns the input as it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9g-uOq6LD-qW"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 5\n",
    "#    Have fun! Spend a few minutes playing around with the code. Also try changing the activation function to tanh or\n",
    "#    anything else. The goal is to see that really simple input functions with really simple weights can produce really\n",
    "#    complicated-looking nonlinear outputs\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/Hly+CB3AgE35cShYI2YY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
