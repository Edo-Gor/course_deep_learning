{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "le5MsLuthBqv"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 9.79\n",
    "#    The importance of equal batch sizes\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waCpZrD-9UFQ"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data                 import DataLoader,TensorDataset\n",
    "from sklearn.model_selection          import train_test_split\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from IPython                          import display\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZI0nNO1Y-OzH"
   },
   "outputs": [],
   "source": [
    "# %% Generate some synthetic data\n",
    "\n",
    "# Parameters\n",
    "n_clust = 200\n",
    "th = np.linspace(0,4*np.pi,n_clust)\n",
    "r1 = 10\n",
    "r2 = 15\n",
    "\n",
    "# Data\n",
    "a = [ r1*np.cos(th) + np.random.randn(n_clust)*3,\n",
    "      r1*np.sin(th) + np.random.randn(n_clust)  ]\n",
    "b = [ r2*np.cos(th) + np.random.randn(n_clust),\n",
    "      r2*np.sin(th) + np.random.randn(n_clust)*3]\n",
    "\n",
    "labels_np = np.vstack(( np.zeros((n_clust,1)),np.ones((n_clust,1)) ))\n",
    "data_np   = np.hstack((a,b)).T\n",
    "\n",
    "data   = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1746897848442,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "2vUsdfGjN6YR",
    "outputId": "1d01a1f1-5de7-4309-94fb-ba3a90a584fb"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'s')\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'o')\n",
    "plt.title(\"Some nonlinear data clusters\")\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "\n",
    "plt.savefig('figure39_batching_regularisation_batch_size.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure39_batching_regularisation_batch_size.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMy8kGbdOgfM"
   },
   "outputs": [],
   "source": [
    "# %% Split into train and test data\n",
    "\n",
    "# Split with scikitlearn\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size=0.1)\n",
    "\n",
    "# Convert into PyTorch datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Convert into DataLoader objects\n",
    "batch_size_tr = 16\n",
    "batch_size_tt = test_data.tensors[0].shape[0]-20\n",
    "train_loader  = DataLoader(train_data,batch_size=batch_size_tr,shuffle=True,drop_last=True)\n",
    "test_loader   = DataLoader(test_data,batch_size=batch_size_tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1746899531051,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "bxleQH6oPonF",
    "outputId": "7a9c8662-5f81-4e2c-de2d-9ab6573e946c"
   },
   "outputs": [],
   "source": [
    "# %% Check sizes of data batches\n",
    "\n",
    "for X,y in test_loader:\n",
    "    print(X.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7dZG1GYQm0n"
   },
   "outputs": [],
   "source": [
    "# %% Model class\n",
    "\n",
    "class model_class(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Layers\n",
    "        self.input  = nn.Linear(  2,128)\n",
    "        self.hidden = nn.Linear(128,128)\n",
    "        self.output = nn.Linear(128,1)\n",
    "\n",
    "    # Forward propagation\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOegWmQ8RYpe"
   },
   "outputs": [],
   "source": [
    "# %% Function to generate the model\n",
    "\n",
    "def gen_model():\n",
    "\n",
    "    # Generate instance of model class\n",
    "    ANN = model_class()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    loss_fun  = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(ANN.parameters(),lr=0.01)\n",
    "\n",
    "    return ANN,loss_fun,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OST-dIvFRYc6"
   },
   "outputs": [],
   "source": [
    "# %% Function to train the model\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 500\n",
    "\n",
    "def train_model(ANN,loss_fun,optimizer):\n",
    "\n",
    "    # Initialise accuracies\n",
    "    train_acc = []\n",
    "    test_acc  = []\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        # Loop over data batches\n",
    "        batch_acc = []\n",
    "        for X,y in train_loader:\n",
    "\n",
    "            # Forward propagation, loss, and backpropagation\n",
    "            yHat = ANN(X)\n",
    "            loss = loss_fun(yHat,y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Batch accuracy\n",
    "            batch_acc.append( 100*torch.mean(((yHat>0)==y).float()).item() )\n",
    "\n",
    "        # Average batch accuracy\n",
    "        train_acc.append(np.mean(batch_acc))\n",
    "\n",
    "        # Test accuracy (but averaging over 2 batches only!)\n",
    "        tmp_acc = []\n",
    "        for X,y in test_loader:\n",
    "            yHat = ANN(X)\n",
    "            tmp_acc.append( 100*torch.mean(((yHat>0)==y).float()).item() )\n",
    "\n",
    "        test_acc.append(np.mean(tmp_acc))\n",
    "\n",
    "    # Output\n",
    "    return train_acc,test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjAOv2g3Trq1"
   },
   "outputs": [],
   "source": [
    "# %% Test model\n",
    "\n",
    "ANN,loss_fun,optimizer = gen_model()\n",
    "train_acc,test_acc = train_model(ANN,loss_fun,optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1746899584917,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "TNQ8t0yBT80v",
    "outputId": "e7bbef2d-e5ab-4144-cc01-5956bd86f23c"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(train_acc,'s')\n",
    "plt.plot(test_acc,'o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train and test accuracy - (un)balanced test batches')\n",
    "\n",
    "plt.savefig('figure40_batching_regularisation_batch_size.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure40_batching_regularisation_batch_size.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPbuT+CwGuacXLrdqcALyZ5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
