{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajZQZPTAL35r"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 12.125\n",
    "#    Save and load trained model\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oH8Ro002LsPZ"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas              as pd\n",
    "import scipy.stats         as stats\n",
    "import time\n",
    "\n",
    "from torch.utils.data                 import DataLoader,TensorDataset\n",
    "from sklearn.model_selection          import train_test_split\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from IPython                          import display\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJokslogtW1t"
   },
   "outputs": [],
   "source": [
    "# %% Data\n",
    "\n",
    "# Load data\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# Split labels from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# Normalise data (original range is (0,255))\n",
    "data_norm = data / np.max(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5IiMkI-v6EI"
   },
   "outputs": [],
   "source": [
    "# %% Create train and test datasets\n",
    "\n",
    "# Convert to tensor (float and integers)\n",
    "data_tensor   = torch.tensor(data_norm).float()\n",
    "labels_tensor = torch.tensor(labels).long()\n",
    "\n",
    "# Split data with scikitlearn (10% test data)\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data_tensor,labels_tensor,test_size=0.1)\n",
    "\n",
    "# Convert to PyTorch datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Convert into DataLoader objects\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwIRPPNPWeko"
   },
   "outputs": [],
   "source": [
    "# %% Model class\n",
    "\n",
    "# %% Function to generate the model\n",
    "#    Keep flexibly loop over model depth/breadth, add flexibility over optimizer\n",
    "\n",
    "def gen_model():\n",
    "\n",
    "    class mnist_FFN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            # Architecture\n",
    "            self.input  = nn.Linear(784,64)\n",
    "            self.hid1   = nn.Linear( 64,32)\n",
    "            self.hid2   = nn.Linear( 32,32)\n",
    "            self.output = nn.Linear( 32,10)\n",
    "\n",
    "        # Forward propagation\n",
    "        def forward(self,x):\n",
    "\n",
    "            x = F.relu(self.input(x))\n",
    "            x = F.relu(self.hid1(x))\n",
    "            x = F.relu(self.hid2(x))\n",
    "            x = torch.log_softmax(self.output(x),axis=1)\n",
    "\n",
    "            return x\n",
    "\n",
    "    # Create model instance\n",
    "    ANN = mnist_FFN()\n",
    "\n",
    "    # Loss function\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.SGD(ANN.parameters(),lr=0.01)\n",
    "\n",
    "    return ANN,loss_fun,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71Nxc5SvlrNV"
   },
   "outputs": [],
   "source": [
    "# %% Function to train the model\n",
    "\n",
    "def train_model():\n",
    "\n",
    "    # Parameters, model instance, inizialise vars\n",
    "    num_epochs = 10\n",
    "    ANN,loss_fun,optimizer = gen_model()\n",
    "\n",
    "    losses    = []\n",
    "    train_acc = []\n",
    "    test_acc  = []\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        # Loop over training batches\n",
    "        batch_acc  = []\n",
    "        batch_loss = []\n",
    "\n",
    "        for X,y in train_loader:\n",
    "\n",
    "            # Forward propagation and loss\n",
    "            yHat = ANN(X)\n",
    "            loss = loss_fun(yHat,y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Loss and accuracy from this batch\n",
    "            batch_loss.append( loss.item() )\n",
    "            batch_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "        losses.append( np.mean(batch_loss) )\n",
    "        train_acc.append( np.mean(batch_acc) )\n",
    "\n",
    "        # Test accuracy\n",
    "        ANN.eval()\n",
    "        with torch.no_grad():\n",
    "            X,y = next(iter(test_loader))\n",
    "            yHat = ANN(X)\n",
    "            test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "        ANN.train()\n",
    "\n",
    "    return train_acc,test_acc,losses,ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "tEzSoZUUlsrE"
   },
   "outputs": [],
   "source": [
    "# %% Run the model\n",
    "\n",
    "train_acc,test_acc,losses,ANN = train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1754152272479,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "ZGaEX_qBlsWt",
    "outputId": "55d73764-591f-4ac8-d9f2-55d308b1365d"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "phi = (1 + np.sqrt(5)) / 2\n",
    "fig,ax = plt.subplots(1,2,figsize=(1.5*phi*6,6))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(train_acc,label='Train')\n",
    "ax[1].plot(test_acc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {test_acc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig('figure35_save_load_trained_models.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure35_save_load_trained_models.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1754152362904,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "Mvjz-o1Qn6V9",
    "outputId": "2252ae15-c47a-4d39-f351-35b7767e0369"
   },
   "outputs": [],
   "source": [
    "# %% Save trained model\n",
    "\n",
    "torch.save(ANN.state_dict(),'trained_model.pt')\n",
    "files.download('trained_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1754152482834,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "s8tBpqjPoZKD",
    "outputId": "d2aef4f3-c045-410b-cec0-3c2bee9da82d"
   },
   "outputs": [],
   "source": [
    "# %% Load the model under a different name\n",
    "\n",
    "# Generate 2 instances of the same model\n",
    "model_1 = gen_model()[0]\n",
    "model_2 = gen_model()[0]\n",
    "\n",
    "# Replace one model's weights with those of the trained model\n",
    "model_1.load_state_dict(torch.load('trained_model.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1754152917994,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "IZqJUjkUosWe",
    "outputId": "76f5b3be-27f2-4240-a4ec-23ffbbd1339e"
   },
   "outputs": [],
   "source": [
    "# %% Show that they are actually the same\n",
    "\n",
    "# Get test data\n",
    "X,y = next(iter(test_loader))\n",
    "\n",
    "# Predict with the base model and with the 2 new models, same data\n",
    "yhat_0 = ANN(X)\n",
    "yHat_1 = model_1(X)\n",
    "yHat_2 = model_2(X)\n",
    "\n",
    "# Plotting (output node number 6)\n",
    "phi = (1 + np.sqrt(5)) / 2\n",
    "fig = plt.figure(figsize=(1.5*phi*6,6))\n",
    "\n",
    "plt.plot(yhat_0[:,5].detach(),'b',label='Original model')\n",
    "plt.plot(yHat_1[:,5].detach(),'ro',label='Reloaded model')\n",
    "plt.plot(yHat_2[:,5].detach(),'mx',label='Not loaded model')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Stimulus index')\n",
    "plt.ylabel('Model output for node \"6\"')\n",
    "plt.xlim([1000,1100])\n",
    "\n",
    "plt.savefig('figure36_save_load_trained_models.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure36_save_load_trained_models.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDKk9OEVCMDXp1xJb8d3xf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
