{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "le5MsLuthBqv"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 8.66\n",
    "#    Cross-validation - DataLoader\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ty5MFy8KhV0e"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data                 import DataLoader,TensorDataset\n",
    "from sklearn.model_selection          import train_test_split\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jE62ETBn8w2B"
   },
   "outputs": [],
   "source": [
    "# %% Import Iris dataset\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# Convert from pandas df to tensor\n",
    "data = torch.tensor(iris[iris.columns[0:4]].values).float()\n",
    "\n",
    "# Species to numbers\n",
    "labels = torch.zeros(len(data),dtype=torch.long)\n",
    "labels[iris.species=='setosa']     = 0\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica']  = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YS5UCmouSfNJ"
   },
   "outputs": [],
   "source": [
    "# %% How to use DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1743940665464,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "iyjIhvtCRDHV",
    "outputId": "da32afeb-8e47-445a-b4f6-c5ffc78ea6d2"
   },
   "outputs": [],
   "source": [
    "# Fake dataset\n",
    "\n",
    "fake_data   = np.tile( np.array([1,2,3,4]),(10,1) ) + np.tile( 10*np.arange(1,11),(4,1) ).T\n",
    "fake_labels = np.arange(10)>4\n",
    "\n",
    "print(fake_data)\n",
    "print()\n",
    "print(fake_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1743940938691,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "e24G0NZgSiy8",
    "outputId": "b67e164b-caf9-4f9e-c6e0-fa05703c8bda"
   },
   "outputs": [],
   "source": [
    "# %% Use DataLoader to shuffle the data\n",
    "\n",
    "# DataLoader object\n",
    "fake_data_LDr = DataLoader(fake_data,shuffle=True)\n",
    "\n",
    "# Print sizes and data\n",
    "print(fake_data_LDr.batch_size)\n",
    "print(fake_data_LDr)\n",
    "print()\n",
    "\n",
    "# To see the content, you have to iterate over it\n",
    "for i,sample in enumerate(fake_data_LDr):\n",
    "  print(i,sample,sample.shape)\n",
    "\n",
    "# But we still don't see the labels!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1743941413221,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "nbTiAY63_FgM",
    "outputId": "83cf641b-d3f9-4bb0-c24e-b7bf3fbe8b07"
   },
   "outputs": [],
   "source": [
    "# %% Create a Dataset that contains data and labels\n",
    "\n",
    "# Merge data and labels into a Dataset object\n",
    "fake_Dataset = TensorDataset(torch.tensor(fake_data),torch.tensor(fake_labels))\n",
    "\n",
    "print(fake_Dataset.tensors)\n",
    "print()\n",
    "\n",
    "# Now create another DataLoader object to shuffle the data\n",
    "fake_data_LDr = DataLoader(fake_Dataset, shuffle=True)\n",
    "\n",
    "# Print data\n",
    "for data,label in fake_data_LDr:\n",
    "  print(data,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHeFkCnrARRl"
   },
   "outputs": [],
   "source": [
    "# %% Use scikitlearn to then split the data\n",
    "\n",
    "# Split\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(fake_data,fake_labels,test_size=0.2)\n",
    "\n",
    "# Convert back to PyTorch dataset\n",
    "train_data = TensorDataset( torch.tensor(train_data),torch.tensor(train_labels) )\n",
    "test_data  = TensorDataset( torch.tensor(test_data),torch.tensor(test_labels) )\n",
    "\n",
    "# Convert back to DataLoader to specify the batch sizes and shuffle\n",
    "train_data_LDr = DataLoader(train_data,batch_size=4)\n",
    "test_data_LDr  = DataLoader(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1743942309062,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "6Sld2MNBDOjn",
    "outputId": "51fd140b-bda0-499c-8239-fec20d80bbd5"
   },
   "outputs": [],
   "source": [
    "# %% Examine the contents of the DataLoader\n",
    "\n",
    "print('Training data:')\n",
    "for batch,label in train_data_LDr:\n",
    "    print(batch,label)\n",
    "    print()\n",
    "\n",
    "print('Test data:')\n",
    "for batch,label in test_data_LDr:\n",
    "    print(batch,label)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTrHBaXZEKKA"
   },
   "outputs": [],
   "source": [
    "# %% Now back to the actual data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pG4Hk2i8EeVA"
   },
   "outputs": [],
   "source": [
    "# %% Split with scikitlearn\n",
    "\n",
    "# Split\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,train_size=0.8,shuffle=True)\n",
    "\n",
    "# Convert to PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Convert to DataLoader (soft-code for 1 test batch)\n",
    "batch_size     = 12\n",
    "train_data_LDr = DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "test_data_LDr  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1743944262000,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "1_4doCJ3F8r2",
    "outputId": "daf1ece5-b324-4cfd-c5bf-79d9d8cf278a"
   },
   "outputs": [],
   "source": [
    "# %% Check sizes of data batches\n",
    "\n",
    "for X,y in train_data_LDr:\n",
    "  print(X.shape,y.shape)\n",
    "\n",
    "print()\n",
    "print(X,y)\n",
    "\n",
    "for X,y in test_data_LDr:\n",
    "  print(X.shape,y.shape)\n",
    "\n",
    "print()\n",
    "print(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoYjb-xWGiOZ"
   },
   "outputs": [],
   "source": [
    "# %% Function to generate the model\n",
    "\n",
    "def gen_model():\n",
    "\n",
    "    # Architecture\n",
    "    ANNiris = nn.Sequential(\n",
    "                 nn.Linear(4,64),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(64,64),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(64,3)\n",
    "                 )\n",
    "\n",
    "    # Loss function\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.SGD(ANNiris.parameters(),lr=0.01)\n",
    "\n",
    "    return ANNiris,loss_fun,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iu3TZz2GvjB"
   },
   "outputs": [],
   "source": [
    "# %% Function to train the model (in mini batches)\n",
    "\n",
    "# Global parameters\n",
    "num_epochs = 500\n",
    "\n",
    "# Function\n",
    "def train_model():\n",
    "\n",
    "    # Preallocate losses\n",
    "    losses = torch.zeros(num_epochs)\n",
    "\n",
    "    # Initialise accuracies as empty\n",
    "    train_acc = []\n",
    "    test_acc  = []\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        # Loop over batches\n",
    "        batch_acc  = []\n",
    "        batch_loss = torch.zeros(1)\n",
    "        for X,y in train_data_LDr:\n",
    "\n",
    "            # Forward propagation\n",
    "            yHat = ANNiris(X)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fun(yHat,y)\n",
    "            batch_loss += loss\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Train accuracy for this batch\n",
    "            batch_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()).item() )\n",
    "\n",
    "        # Compute average train accuracy and loss for this epoch (average of batch_loss)\n",
    "        train_acc.append( np.mean(batch_acc) )\n",
    "        losses[epoch_i] = batch_loss/len(train_data_LDr)\n",
    "\n",
    "        # Compute test accuracy (just one test bacth)\n",
    "        X,y = next(iter(test_data_LDr))\n",
    "        pred_labels = torch.argmax( ANNiris(X),axis=1 )\n",
    "        test_acc.append( 100*torch.mean((pred_labels==y).float()).item() )\n",
    "\n",
    "    return train_acc,test_acc,losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x30_motLa6iO"
   },
   "outputs": [],
   "source": [
    "# %% Test the model once\n",
    "\n",
    "ANNiris,loss_fun,optimizer = gen_model()\n",
    "train_acc,test_acc,losses  = train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1743944609964,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "_kUPRjnSbv_v",
    "outputId": "bded2132-eea1-421a-c721-83a3aad742de"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(train_acc,'o-',alpha=.75)\n",
    "plt.plot(test_acc,'s-',alpha=.75)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train/test example')\n",
    "\n",
    "plt.savefig('figure8_cross_validation_dataloader.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure8_cross_validation_dataloader.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ptt-jON_KH-2"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 1\n",
    "#    Read the help doc for the train_test_split() function, in particular to understand what the 'shuffle' option does.\n",
    "#    What is the default value? Run the code again, switching the shuffling off. How does that affect model performance? Why?\n",
    "\n",
    "# Default is True, and if turned to False the split is executed always in the same way, with the first n% samples\n",
    "# being the train samples, and the remaining the test sample. In this case, the test dataset is always made up of\n",
    "# a set of \"2\" labels, and as one would imagine, the model does not perform so well because it is trained mostly\n",
    "# with labels \"0\" and \"1\" and then asked to classify labels \"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1743944698668,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "SZ_V8uWiKZS9",
    "outputId": "bb99ff03-4833-4714-bd44-4561fa9acf5c"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 2\n",
    "#    The model training loop does not keep track of the losses. Modify the code to store the loss value on each epoch, include\n",
    "#    it as an output of the training function, and then make a plot of the training losses. Try to do it without looking\n",
    "#    at other code files!\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(losses.detach(),'o-',alpha=.75)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend(['Losses'])\n",
    "plt.title('Losses over epochs')\n",
    "\n",
    "plt.savefig('figure10_cross_validation_dataloader_extra2.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure10_cross_validation_dataloader_extra2.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOmaBG8pDUXljjPAllhInPY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
