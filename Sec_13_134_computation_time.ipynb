{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hll0rWex3z2F"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 13.14\n",
        "#    Computation time\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e_D-dpe323u"
      },
      "outputs": [],
      "source": [
        "# %% Two ways to track the time needed to fit models (exact and rough)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rZx3Hulk320h"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F-GyBIY332yk"
      },
      "outputs": [],
      "source": [
        "# %% Function to get the data\n",
        "\n",
        "# Load data\n",
        "data_all = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Function\n",
        "def get_dataset(digits=None,n_per_digits=None):\n",
        "\n",
        "    # Remove labels (i.e., numbers IDs) from dataset\n",
        "    labels = data_all[:,0]\n",
        "    data   = data_all[:,1:]\n",
        "\n",
        "    # Normalize to [0,1]\n",
        "    data_norm = data / np.max(data)\n",
        "\n",
        "    # Covert to tensor\n",
        "    data_T   = torch.tensor(data_norm).float()\n",
        "    labels_T = torch.tensor(labels).long()\n",
        "\n",
        "    # Split data with scikitlearn\n",
        "    train_data,test_data, train_labels,test_labels = train_test_split(data_T,labels_T,test_size=0.1)\n",
        "\n",
        "    # Select subsample\n",
        "    if digits is not None and n_per_digits is not None:\n",
        "\n",
        "        keep_indices = np.zeros(labels.shape[0],dtype=bool)\n",
        "        train_labels_np = train_labels.numpy()\n",
        "\n",
        "        for lbl in np.unique(train_labels_np):\n",
        "\n",
        "            idx = np.where(train_labels_np == lbl)[0]\n",
        "\n",
        "            if lbl in digits:\n",
        "\n",
        "                idx = np.random.choice(idx,n_per_digits,replace=False)\n",
        "\n",
        "            keep_indices[idx] = True\n",
        "\n",
        "        train_data   = train_data[keep_indices]\n",
        "        train_labels = train_labels[keep_indices]\n",
        "\n",
        "    # PyTorch datasets\n",
        "    train_data = TensorDataset(train_data,train_labels)\n",
        "    test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "    # DataLoader objects\n",
        "    batch_size   = 32\n",
        "    train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "    test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n",
        "\n",
        "    return train_loader,test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PW0pk8FbmxoC"
      },
      "outputs": [],
      "source": [
        "# %% Model class\n",
        "\n",
        "def gen_model():\n",
        "\n",
        "    class model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Architecture\n",
        "            self.input  = nn.Linear(784,64 )\n",
        "            self.hid1   = nn.Linear( 64,32 )\n",
        "            self.hid2   = nn.Linear( 32,32 )\n",
        "            self.output = nn.Linear( 32,10 )\n",
        "\n",
        "        def forward(self,x):\n",
        "            x = F.relu(self.input(x))\n",
        "            x = F.relu(self.hid1(x))\n",
        "            x = F.relu(self.hid2(x))\n",
        "\n",
        "            return self.output(x)\n",
        "\n",
        "    # Model instance, loss function, and optimizer\n",
        "    ANN       = model()\n",
        "    loss_fun  = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(ANN.parameters(),lr=0.01)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q7-p5EnSmxgj"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    # Start timing (Option 1 - exact timing)\n",
        "    timer_in_func = time.process_time()\n",
        "\n",
        "    # Epochs and fresh model instance\n",
        "    num_epochs = 10\n",
        "    ANN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "    # Preallocate vars\n",
        "    losses    = torch.zeros(num_epochs)\n",
        "    train_acc = torch.zeros(num_epochs)\n",
        "    test_acc  = torch.zeros(num_epochs)\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training data batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward pass, backpropagation, and optimizer step\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "            batch_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        losses[epoch_i]    = np.mean(batch_loss).item()\n",
        "        train_acc[epoch_i] = np.mean(batch_acc).item()\n",
        "\n",
        "        # Test accuracy\n",
        "        ANN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = ANN(X)\n",
        "            test_acc[epoch_i] = 100*torch.mean((torch.argmax(yHat,axis=1)==y).float())\n",
        "\n",
        "        ANN.train()\n",
        "\n",
        "        # Stop timing (print every 5h epoch)\n",
        "        comp_time = time.process_time() - timer_in_func\n",
        "        if (epoch_i + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch_i+1}/{num_epochs}, elapsed time: {comp_time:.2f} s, test accuracy: {test_acc[-1]:.0f}%\")\n",
        "\n",
        "    return train_acc,test_acc,losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owWebbeNmxdL",
        "outputId": "43c05588-d512-4cec-ddf5-87a6fe14635e"
      },
      "outputs": [],
      "source": [
        "# %% Fit the model\n",
        "\n",
        "train_loader,test_loader = get_dataset(digits=None,n_per_digits=None)\n",
        "train_acc,test_acc,losses,ANN = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdsDSPLa32se",
        "outputId": "86ab0737-0d58-47f5-b028-512d883aeba7"
      },
      "outputs": [],
      "source": [
        "# %% Fit the model again multiple times\n",
        "\n",
        "# Start timing (Option 2 - rough timing)\n",
        "timer_out_func = time.process_time()\n",
        "\n",
        "for i in range(10):\n",
        "    train_model()\n",
        "\n",
        "exp_time = time.process_time() - timer_out_func\n",
        "print(f\"\\n\\nTotal elapsed experiment time: {exp_time/60:.0f} m\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o67zKiE7Pu5",
        "outputId": "ceab7101-7ba8-45c2-e1e7-d3c8dc9bc453"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Modify the TotalExperimentTime code so that it prints minutes and seconds. For example, 500 seconds is\n",
        "#    8 minutes and 20 seconds.\n",
        "\n",
        "minutes = int(exp_time // 60)\n",
        "seconds = int(exp_time % 60)\n",
        "\n",
        "print(f\"Total elapsed experiment time: {minutes} m {seconds} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLJdWZaY7PrQ"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Modify the code inside the training function so that the display prints on only every 5th epoch.\n",
        "\n",
        "# See modified function above\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
