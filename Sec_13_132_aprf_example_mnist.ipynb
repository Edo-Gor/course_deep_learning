{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajZQZPTAL35r"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 13.132\n",
        "#    APRF example 1: mnist\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oH8Ro002LsPZ"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q2wPIbiuBwdE"
      },
      "outputs": [],
      "source": [
        "# %% Get the data\n",
        "\n",
        "# Load data\n",
        "data_all = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Remove labels (i.e., numbers IDs) from dataset\n",
        "labels = data_all[:,0]\n",
        "data   = data_all[:,1:]\n",
        "\n",
        "# Normalize to [0,1]\n",
        "data_norm = data / np.max(data)\n",
        "\n",
        "# Covert to tensor\n",
        "data_T   = torch.tensor(data_norm).float()\n",
        "labels_T = torch.tensor(labels).long()\n",
        "\n",
        "# Split data with scikitlearn\n",
        "train_data,test_data, train_labels,test_labels = train_test_split(data_T,labels_T,test_size=0.1)\n",
        "\n",
        "# PyTorch datasets\n",
        "train_data = TensorDataset(train_data,train_labels)\n",
        "test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "# DataLoader objects\n",
        "batch_size   = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4Mde_24jCd3G"
      },
      "outputs": [],
      "source": [
        "# %% Model class\n",
        "\n",
        "def gen_model():\n",
        "\n",
        "    class model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Architecture\n",
        "            self.input  = nn.Linear(784,64 )\n",
        "            self.hid1   = nn.Linear( 64,32 )\n",
        "            self.hid2   = nn.Linear( 32,32 )\n",
        "            self.output = nn.Linear( 32,10 )\n",
        "\n",
        "        def forward(self,x):\n",
        "            x = F.relu(self.input(x))\n",
        "            x = F.relu(self.hid1(x))\n",
        "            x = F.relu(self.hid2(x))\n",
        "\n",
        "            return self.output(x)\n",
        "\n",
        "    # Model instance, loss function, and optimizer\n",
        "    ANN       = model()\n",
        "    loss_fun  = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(ANN.parameters(),lr=0.01)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "out6foWBCd0u"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    # Epochs (few to keep some varaibility in performace) and fresh model instance\n",
        "    num_epochs = 10\n",
        "    ANN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "    # Preallocate vars\n",
        "    losses    = torch.zeros(num_epochs)\n",
        "    train_acc = torch.zeros(num_epochs)\n",
        "    test_acc  = torch.zeros(num_epochs)\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training data batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward pass, backpropagation, and optimizer step\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "            batch_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        losses[epoch_i]    = np.mean(batch_loss).item()\n",
        "        train_acc[epoch_i] = np.mean(batch_acc).item()\n",
        "\n",
        "        # Test accuracy\n",
        "        ANN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = ANN(X)\n",
        "            test_acc[epoch_i] = 100*torch.mean((torch.argmax(yHat,axis=1)==y).float())\n",
        "\n",
        "        ANN.train()\n",
        "\n",
        "    return train_acc,test_acc,losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_UfQ1TnzCdx6"
      },
      "outputs": [],
      "source": [
        "# %% Fit the model\n",
        "\n",
        "train_acc,test_acc,losses,ANN = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "j1GZsHqnCdvx",
        "outputId": "ac759694-6977-40da-f43b-d25493af2362"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(1.5*phi*6,6))\n",
        "\n",
        "ax[0].plot(losses)\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_ylim([0,3])\n",
        "ax[0].set_title('Model loss')\n",
        "\n",
        "ax[1].plot(train_acc,label='Train')\n",
        "ax[1].plot(test_acc,label='Test')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy (%)')\n",
        "ax[1].set_ylim([10,100])\n",
        "ax[1].set_title(f'Final model test accuracy: {test_acc[-1]:.2f}%')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.savefig('figure6_aprf_example_mnist.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure6_aprf_example_mnist.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glxFfQl4CdtV",
        "outputId": "4fb56815-d82b-407b-ce89-abe522c70cb1"
      },
      "outputs": [],
      "source": [
        "# %% Get data to compute performance measures on train and test data\n",
        "\n",
        "# Predictions for (all) training data (i.e. raw output of last layer)\n",
        "yHat        = ANN(train_loader.dataset.tensors[0])\n",
        "train_preds = torch.argmax(yHat,axis=1)\n",
        "print(train_preds.shape)\n",
        "\n",
        "# Predictions for test data (i.e. raw output of last layer)\n",
        "yHat       = ANN(test_loader.dataset.tensors[0])\n",
        "test_preds = torch.argmax(yHat,axis=1)\n",
        "print(test_preds.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQSM8NYwDulS",
        "outputId": "ee127f01-0cc6-4d36-8292-d8df02f6029d"
      },
      "outputs": [],
      "source": [
        "# %% Interlude on computing performance metrics in multiclass data\n",
        "\n",
        "# For the MNIST dataset, we have 10 classes, so we need 10 performance values,\n",
        "# be it accuracy, precision, recall, F1, or others; let's consider here\n",
        "# precision as example\n",
        "\n",
        "# Option 1: compute precision for each class (i.e., each digit)\n",
        "precision_1 = skm.precision_score(train_loader.dataset.tensors[1],train_preds,average=None)\n",
        "print(precision_1)\n",
        "\n",
        "# Option 2: compute average precision, weighted by N\n",
        "precision_2 = skm.precision_score(train_loader.dataset.tensors[1],train_preds,average='weighted')\n",
        "print(precision_2)\n",
        "\n",
        "# Option 3: compute average precision, unweighted (same as 'weighted' if category samples are equal)\n",
        "precision_3 = skm.precision_score(train_loader.dataset.tensors[1],train_preds,average='macro')\n",
        "print(precision_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "v213h6k0Dui5"
      },
      "outputs": [],
      "source": [
        "# %% Compute performance measures on train and test data\n",
        "\n",
        "# Preallocate\n",
        "train_metrics = np.zeros(4)\n",
        "test_metrics  = np.zeros(4)\n",
        "\n",
        "# Training performance measures (accuracy is already an overall measure)\n",
        "train_metrics[0] = skm.accuracy_score (train_loader.dataset.tensors[1],(train_preds).float())\n",
        "train_metrics[1] = skm.precision_score(train_loader.dataset.tensors[1],(train_preds).float(),average='weighted')\n",
        "train_metrics[2] = skm.recall_score   (train_loader.dataset.tensors[1],(train_preds).float(),average='weighted')\n",
        "train_metrics[3] = skm.f1_score       (train_loader.dataset.tensors[1],(train_preds).float(),average='weighted')\n",
        "\n",
        "# Test performance measures\n",
        "test_metrics[0] = skm.accuracy_score (test_loader.dataset.tensors[1],(test_preds).float())\n",
        "test_metrics[1] = skm.precision_score(test_loader.dataset.tensors[1],(test_preds).float(),average='weighted')\n",
        "test_metrics[2] = skm.recall_score   (test_loader.dataset.tensors[1],(test_preds).float(),average='weighted')\n",
        "test_metrics[3] = skm.f1_score       (test_loader.dataset.tensors[1],(test_preds).float(),average='weighted')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "BiLLv6DUDugY",
        "outputId": "631462ee-0d26-416e-a982-a63859aa4ab2"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(6*phi,6))\n",
        "\n",
        "plt.bar(np.arange(4)-.1,train_metrics,.5)\n",
        "plt.bar(np.arange(4)+.1,test_metrics,.5)\n",
        "plt.xticks([0,1,2,3],['Accuracy','Precision','Recall','F1-score'])\n",
        "plt.ylim([.5,.7])\n",
        "plt.legend(['Train','Test'])\n",
        "plt.title('Performance metrics')\n",
        "\n",
        "plt.savefig('figure7_aprf_example_mnist.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure7_aprf_example_mnist.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "EfsqEajrDueK",
        "outputId": "4b2e7d36-d7ba-46a4-b0b5-dc0856dc1c41"
      },
      "outputs": [],
      "source": [
        "# %% Check for possible biases towards certain digits\n",
        "\n",
        "# Class-specific precision and recall for test data\n",
        "precision = skm.precision_score(test_loader.dataset.tensors[1],test_preds,average=None)\n",
        "recall    = skm.recall_score   (test_loader.dataset.tensors[1],test_preds,average=None)\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(1.5*6*phi,6))\n",
        "\n",
        "plt.bar(np.arange(10)-.15,precision,.5)\n",
        "plt.bar(np.arange(10)+.15,recall,.5)\n",
        "plt.xticks(range(10),range(10))\n",
        "plt.ylim([.1,1])\n",
        "plt.xlabel('Digit')\n",
        "plt.legend(['Precision','Recall'])\n",
        "plt.title('Category-specific performance metrics')\n",
        "\n",
        "plt.savefig('figure8_aprf_example_mnist.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure8_aprf_example_mnist.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "-3l8QG9IIX1F",
        "outputId": "a9e7e053-e148-41d7-84e9-b3d1f5941bbc"
      },
      "outputs": [],
      "source": [
        "# %% Potting\n",
        "\n",
        "# Confusion matrices\n",
        "train_conf = skm.confusion_matrix(train_loader.dataset.tensors[1],train_preds,normalize='true')\n",
        "test_conf  = skm.confusion_matrix(test_loader.dataset.tensors[1],test_preds,normalize='true')\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(phi*6,6),constrained_layout=True)\n",
        "\n",
        "# Training confusion matrix\n",
        "ax[0].imshow(train_conf,'Blues',vmax=.1)\n",
        "ax[0].set_xticks(range(10))\n",
        "ax[0].set_yticks(range(10))\n",
        "ax[0].set_title('TRAIN confusion matrix')\n",
        "ax[0].set_xlabel('True number')\n",
        "ax[0].set_xlabel('Predicted number')\n",
        "ax[0].set_ylabel('True number')\n",
        "\n",
        "# Test confusion matrix\n",
        "img = ax[1].imshow(test_conf,cmap='Blues',vmax=.1)\n",
        "ax[1].set_xticks(range(10))\n",
        "ax[1].set_yticks(range(10))\n",
        "ax[1].set_title('TEST confusion matrix')\n",
        "ax[1].set_xlabel('Predicted number')\n",
        "ax[1].set_ylabel('True number')\n",
        "fig.colorbar(img,ax=ax[1],shrink=0.6)\n",
        "\n",
        "plt.savefig('figure9_aprf_example_mnist.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure9_aprf_example_mnist.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CFiWGa8IXyM"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    The Adam optimizer is pretty amazing, isn't it? Change the code to get the overall test accuracy between 50% and 80%.\n",
        "#    You can consider changing the optimizer, learning rate, and number of epochs. Then show the performance metrics.\n",
        "#    Are there systematic difficulties with some numbers, or simply a general decline in performance overall?\n",
        "\n",
        "# Trying with SGD, lr=0.001 and 25 epochs. If we look at the overall pattern of\n",
        "# APRF, it seems like the performance is going down in general; when looking at\n",
        "# precision and recall for each digit, however, the picture changes a lot, the\n",
        "# metrics oscillates between ~0.1 and ~0.9, with some digits doing particularly\n",
        "# bad in general, some doing worse on the precision (e.g., 0, 6, 7), and some\n",
        "# doing worse on the recall (e.g., 2, 3, 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "nR36RkhyDubp",
        "outputId": "70da11a2-52ce-4e7f-eb09-b290e3d8bffb"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Are the y-axis and color-limits still appropriate? Modify the visualization code so that the graphs are adaptive\n",
        "#    to the numerical values of the performance metrics and confusion matrices.\n",
        "\n",
        "# That can be done by flexibly setting plt.ylim([]) and vmin/vmax. Note how on\n",
        "# the confusion matrices one can now see better the deflection in performance\n",
        "# for some of the digits (e.g., 2, 3, 4)\n",
        "\n",
        "# Plot 1\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(6*phi,6))\n",
        "\n",
        "plt.bar(np.arange(4)-.1,train_metrics,.5)\n",
        "plt.bar(np.arange(4)+.1,test_metrics,.5)\n",
        "plt.xticks([0,1,2,3],['Accuracy','Precision','Recall','F1-score'])\n",
        "ymin = min(train_metrics.min(), test_metrics.min())\n",
        "ymax = max(train_metrics.max(), test_metrics.max())\n",
        "plt.ylim([ymin*0.95,ymax*1.05])\n",
        "plt.legend(['Train','Test'])\n",
        "plt.title('Performance metrics')\n",
        "\n",
        "plt.savefig('figure14_aprf_example_mnist_extra2.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure14_aprf_example_mnist_extra2.png')\n",
        "\n",
        "# Plot 2\n",
        "precision = skm.precision_score(test_loader.dataset.tensors[1],test_preds,average=None)\n",
        "recall    = skm.recall_score   (test_loader.dataset.tensors[1],test_preds,average=None)\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(1.5*6*phi,6))\n",
        "\n",
        "plt.bar(np.arange(10)-.15,precision,.5)\n",
        "plt.bar(np.arange(10)+.15,recall,.5)\n",
        "plt.xticks(range(10),range(10))\n",
        "ymin = min(precision.min(),recall.min())\n",
        "ymax = max(precision.max(),recall.max())\n",
        "plt.ylim([ymin*0.95,ymax*1.05])\n",
        "plt.xlabel('Digit')\n",
        "plt.legend(['Precision','Recall'])\n",
        "plt.title('Category-specific performance metrics')\n",
        "\n",
        "plt.savefig('figure15_aprf_example_mnist_extra2.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure15_aprf_example_mnist_extra2.png')\n",
        "\n",
        "# Plot 3\n",
        "train_conf = skm.confusion_matrix(train_loader.dataset.tensors[1],train_preds,normalize='true')\n",
        "test_conf  = skm.confusion_matrix(test_loader.dataset.tensors[1],test_preds,normalize='true')\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(phi*6,6),constrained_layout=True)\n",
        "\n",
        "vmin = min(train_conf.min(),test_conf.min())\n",
        "vmax = max(train_conf.max(),test_conf.max())\n",
        "\n",
        "ax[0].imshow(train_conf,'Blues',vmin=vmin,vmax=vmax)\n",
        "ax[0].set_xticks(range(10))\n",
        "ax[0].set_yticks(range(10))\n",
        "ax[0].set_title('TRAIN confusion matrix')\n",
        "ax[0].set_xlabel('True number')\n",
        "ax[0].set_xlabel('Predicted number')\n",
        "ax[0].set_ylabel('True number')\n",
        "\n",
        "img = ax[1].imshow(test_conf,cmap='Blues',vmin=vmin,vmax=vmax)\n",
        "ax[1].set_xticks(range(10))\n",
        "ax[1].set_yticks(range(10))\n",
        "ax[1].set_title('TEST confusion matrix')\n",
        "ax[1].set_xlabel('Predicted number')\n",
        "ax[1].set_ylabel('True number')\n",
        "fig.colorbar(img,ax=ax[1],shrink=0.6)\n",
        "\n",
        "plt.savefig('figure16_aprf_example_mnist_extra2.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure16_aprf_example_mnist_extra2.png')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
